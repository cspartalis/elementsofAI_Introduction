{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turing's test\n",
    "Imitation game: A human interrogator interacts w/ two players. One human and one computer. If the interrogator can't understand who is who, then the computer is considered to have reach human-level intelligence.\n",
    "\n",
    "Con: Behaving like human isn't actually a measure of intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese room argument\n",
    "A human, who doesn't speak Chinese, is given a big manual on how to respond to Chinese messages. So the other person of the argument is developing the impression that speaks w/ another person, who speaks Chinese.\n",
    "\n",
    "Performing well specific tasks, doesn't mean you 're intelligent.\n",
    "\n",
    "Although intelligence can be broken down into small mechanical instructions that can be automated, the intelligent behavior of a system is different from actually being intelligent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General vs narrow AI\n",
    "Narrow AI: Handles only one task\n",
    "\n",
    "General AI (AGI): Can handle any intellectual task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strong vs Weak AI\n",
    "It's the difference between being and just acting intelligent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 4\n",
    "\n",
    "### My answer\n",
    "I am going to examine the pros and cons of each definition given in the exercise:\n",
    "\n",
    "1. \"cool things that computers can't do\"\n",
    "Pros: AI is constantly redefined. Some tasks that were considered as AI, are being classified as non-AI\n",
    "Cons: It's kind of ironic definition, since it implies that AI is never going to make any progress, since if something cool is managed to be done by computer, at the same time it stops being considered as AI\n",
    "\n",
    "2. machines imitating intelligent human behavior\n",
    "Pros: Indeed, machines are trying to imitate human behavior, and they are excelling in task that seems really hard for humans.\n",
    "Cons: According to the conclusion of the Chines room argument, eve though intelligence can be broken down into small mechanical instructions that can be automated, the intelligent behavior of a system is different from actually being intelligent.\n",
    "\n",
    "3. autonomous and adaptive systems \n",
    "Pros: Indeed the target is to make machines that performs tasks w/o needing constant guidance and having the ability to improve performance by learning from experience.\n",
    "Cons:  As mentioned before, performing specific tasks that have been explicitly described, is not actually similar to human intelligence.\n",
    "\n",
    "My attempt to define AI:\n",
    "\"Autonomous and adaptive systems, that are trying to imitate specific human tasks\"\n",
    "\n",
    "### Example answer\n",
    "There is no right or wrong answer, but here’s what we think:\n",
    "\n",
    "“Cool things that computers can't do\"\n",
    "\n",
    "The good: this adapts to include new problems in the future, captures a wide range of AI such computer vision, natural language processing.\n",
    "\n",
    "The bad: it rules out any \"solved\" problems, very hard to say what counts as \"cool\".\n",
    "\n",
    "“Machines imitating intelligent human behavior”\n",
    "\n",
    "The good: same as the previous, also imitate is a good word since it doesn't require that the AI solutions should \"be\" intelligent (whatever it means) and instead is is enough to act intelligently.\n",
    "\n",
    "The bad: the definition is almost self-referential in that it immediately leads to the question what is 'intelligent', also this one is too narrow in the sense that it only includes humanlike intelligent behavior and excludes other forms of intelligence such as so called swarm intelligence (intelligence exhibited by for example ant colonies).\n",
    "\n",
    "“Autonomous and adaptive systems”\n",
    "\n",
    "The good: it highlights two main characteristics of AI, captures things like robots, self-driving cars, and so on, also nicely fits machine learning -based AI methods that adapt to the training data.\n",
    "\n",
    "The bad: once again, these lead to further questions and the definition of 'autonomous' in particular isn't very clear (is a vacuum cleaner bot autonomous? How about a spam filter?); furthermore, not all AI systems need to be autonomous and we can in fact often achieve much more by combining human and machine intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
